{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Feature Extraction__ : _An alternative approach to feature selection for_ Dimensionality Reduction.\n",
    "- In feature selection we maintian the original features, we use feature extraction to transform or__project the data onto a new feature space__.\n",
    "- In the context of __dimensionality reduction__, feature extraction can be understood as an approach to __data compression with the goal of maintaining most of th relevant information.__\n",
    "\n",
    "__Note :__ In practice, feature extraction is not only used to improve storage space or computational efficiency of learning algorithm ,  but can also improve the predictive performance by reducing the _curse of dimensionality_ - especially if we are working with _non-regularized_ models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis - unsupervised linear transformation\n",
    "\n",
    "- PCA wildely used across fields, most prominently for feature extraction and dimensionality reduction.\n",
    "- Other applications, in de-noising the signals in stock-market trading, and analysis of genome data and gene expresssions levels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__PCA__ helps to identify patterns based on <u><font style=\"color:#0073e6\">correlation between features</font></u>.<br>\n",
    "__PCA aims__ to <font style=\"color:#0073e6\">find the direction of maximum variance</font> in high-dimensional data and __projects it into a new subspace__ with equal ro less fewer dimensions.</font>\n",
    "> The __orthogonal axes(principal component)__ of new subspace can be interpreted as the directions of maximum variance given the constraint that, new feature are orthogonal to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pca](pca.png)\n",
    "\n",
    "- __x1__ and __x2__ are orignial featues, and __PC1__ and __PC2__ are principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize the approach of PCA:<br>\n",
    "1. Standarize the d-dimensional dataset\n",
    "2. Construct the covariance matrix\n",
    "3. Decompose the covariance matrix into its eigenvectors and eigenvalues.\n",
    "4. Sort the eigenvalues by decreasing order to rank the corresponding eigenvectors.\n",
    "5. select _k_ eigenvectors which corresponds to the _k_ largest eigenvalues, where _k_ is the dimensionality of the new feature subspace $ k \\leq d$\n",
    "6. Construct a projection matrix __W__ form the \"top\" _k_ eigenvectors.\n",
    "7. Transform the _d_-dimensional input dataset __X__ using the projection matrix __W__ to obtain the new _k_-dimensional feature subspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of transformation, __fist principal component will have the larges possible variance, and all consequent principal component will have the largest variance given the constraint that these components are uncorrelated(orthogonal) to other principal components --even if the input features are correlated, the resulting principal component will be mutually orthogonal (uncorrelated).__\n",
    "\n",
    "__Note :__ PCA are highly sensitive to data scaling, we need to standarize feature __prior to PCA__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
