{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Mechanics of TensorFlow\n",
    "\n",
    "## Key Features of TensorFlow\n",
    "\n",
    "1. TensorFlow givesus a scalable, mulitplatform programming interface for implementing and running machine learning algorithms.\n",
    "2. TensorFlow API has been relatively stable and mature since its 1.0 release in 2n017.\n",
    "3. Its ability to work with single or multiple GPUs, This allows users to train machine learning models very efficiently on  large-scale systems.\n",
    "4. TensorFlow has strong growth drivers : development is funded ans supported nu Google, and  so continuous imporvements and contribution from open source developers.\n",
    "5. TensorFlow support mobile deployment, which makes it a very suitable tool for application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow library lets users define operations and functions over tensors asn computational graphs. Tensors are a generalizable matehmatical notation for multidimensional arrays holding data vlaues, where the dimensionality of a tensor a typically referred to as its __rank__.\n",
    "\n",
    "![Tensors image](tensors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the rank and shape of a tensor\n",
    "\n",
    "We can use the _tf.rank_ function to get  the rank of a tensor. It is important to note that _tf.rank_ will return a tensor a soutpt, and in order to get the actual values, we will need to evaluate that tensor.\n",
    "<br>\n",
    "\n",
    "We can get the shape of a tensor _X_ using _X.get-shape()_, whichi will return an object of a special class called _TensorShape_.\n",
    "<br>\n",
    "\n",
    "We can print the shape and use it direclty ofr the shape argumen when creating other tensors, However, we can index only after converting it into a Python list , usign the _as-list_ method of the tensor class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: () (4,) (2, 2)\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "## define the computation graph\n",
    "with g.as_default():\n",
    "    ## define tensors t1, t2, t3\n",
    "    t1 = tf.constant(np.pi)\n",
    "    t2 = tf.constant([1,2,3,4])\n",
    "    t3 = tf.constant([[1,2], [3,4]])\n",
    "    \n",
    "    ## get their ranks\n",
    "    r1 = tf.rank(t1)\n",
    "    r2 = tf.rank(t2)\n",
    "    r3 = tf.rank(t3)\n",
    "    \n",
    "    ## get their shapes\n",
    "    s1 = t1.get_shape()\n",
    "    s2 = t2.get_shape()\n",
    "    s3 = t3.get_shape()\n",
    "    print('Shapes:', s1, s2, s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranks 0 1 2\n",
      "Ranks 0 1 2\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    print('Ranks', sess.run(r1), sess.run(r2),sess.run(r3))\n",
    "    print('Ranks', r1.eval(), r2.eval(),r3.eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Understanding TensorFlow's computation graph\n",
    "\n",
    "TensorFlow relies on building a computatiion graph at tis core, and it uses this computation graph to derive relatinsips between tensor form input all the way to the ouput.\n",
    "\n",
    "- The computation graph is simply a network of nodes. Each node resmebles an operation, which applies a function to its input tensor(s) and returns zeror or more tensors as output.\n",
    "\n",
    "\n",
    "![computation graph ](computation_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TensorFlow build this computation graph and uses it to compute the gradients accordingly. The individual steps for building and compiling such a computation graph in TensorFlow are as follows:\n",
    "\n",
    "1. Instantiate a new, empty computation graph\n",
    "2. Add nodes (tensors and operations) to the computation graph.\n",
    "3. Execute the graph:<br>\n",
    "\n",
    "    a. Start a new session<br>\n",
    "    b. Initialize the varibales in the graph.<br>\n",
    "    c. Run the computation graph in this session.\n",
    "    \n",
    "    \n",
    "Let's create a graph for evaluationg _z = 2x(a-b)+c_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    a = tf.constant(1, name='a_conts')\n",
    "    b = tf.constant(2, name='b_conts')    \n",
    "    c = tf.constant(3, name='c_conts')\n",
    "    \n",
    "    z = 2*(a-b) + c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- If we do __not__ explicitly create ag raph, there is always a default graph, and therfore, all the nodes are added to the default graph.\n",
    "- A TensorFlow sesssion is an environment is which the opeations and tesnors ofa graph cna be exceuted A session object is crated nu calling _tf.session_ that can receive an existing graph (here, g) as an argument as in _tf.session(graph=g)_; otherwise, it will launch the efault frapht,, which might be empty.\n",
    "\n",
    "<br>\n",
    "- Evaluating each tensor involves calling its _eval_ method inside the current session, \n",
    "- When evaluating a specific tensor in the graph, TensorFlow has to execute all the preceding nodes in the graph until it reaches that particular one.\n",
    "- In case there are one or more placeholders, they would need to  be fed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2*(a-b)+c  => 1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    print('2*(a-b)+c  =>', z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Placeholders in TensorFlow\n",
    "\n",
    "- TensorFlow has specil mechnaisms for feeding data, ON e of these mechanisms is the use of placeholder, whicha re predfiened tensors with specific types and shapes.\n",
    "\n",
    "- These tensors are added to the computation graph using the _tf.placeholder_ functin, and they do not contain any data. However, upon the excution of certain nodes in the graph, these placholders need to be fed with data arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Defining placeholders\n",
    "\n",
    "- When defining placeholders, we need to decide what their __shape and type__ should be , according to the shape and type of the data that will be fed through them upon execution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_a = tf.placeholder(shape=(None), dtype= tf.float16, name='a_pla_holde')\n",
    "    tf_b = tf.placeholder(shape=(None), dtype= tf.float16, name='b_pla_holde')    \n",
    "    tf_c = tf.placeholder(shape=(None), dtype= tf.float16, name='c_pla_holde')\n",
    "    \n",
    "    z = 2*(tf_a-tf_b)+tf_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z :  1.0\n",
      "z :  [ 0.  3.]\n",
      "z :  [[ 0.]\n",
      " [ 3.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    feed = {tf_a:1,\n",
    "           tf_b:2,\n",
    "           tf_c:3}\n",
    "    print('z : ', sess.run(z, feed_dict=feed))\n",
    "    \n",
    "    feed = {tf_a:[1,2],\n",
    "           tf_b:[3,2],\n",
    "           tf_c:[4,3]}\n",
    "    print('z : ', sess.run(z, feed_dict=feed))\n",
    "    \n",
    "    feed = {tf_a:[[1],[2]],\n",
    "           tf_b:[[3],[2]],\n",
    "           tf_c:[[4],[3]]}\n",
    "    print('z : ', sess.run(z, feed_dict=feed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A useful feaute of placeholders is that we can spcify _None_ for the dimension that is varying in size. For example, we cna create a placeholder of rank2, where hte firest dimension is unkonwn (or may vary),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_x = tf.placeholder(tf.float32, shape=[None,2], name='tf_x')\n",
    "    x_mean = tf.reduce_mean(tf_x , axis=0, name='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feeding data with shape  (5, 2)\n",
      "Result :  [ 0.62  0.47]\n",
      "Tensor(\"tf_x:0\", shape=(?, 2), dtype=float32)\n",
      "\n",
      "\n",
      "Feeding data with shape  (10, 2)\n",
      "Result :  [ 0.46  0.49]\n",
      "Tensor(\"tf_x:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    x1 = np.random.uniform(low= 0, high=1, size=(5,2))\n",
    "    \n",
    "    print('Feeding data with shape ' , x1.shape)\n",
    "    print('Result : ',sess.run(x_mean, feed_dict={tf_x:x1}))\n",
    "    print(tf_x)    \n",
    "    \n",
    "    print('\\n')\n",
    "    x2 = np.random.uniform(low= 0, high=1, size=(10,2))\n",
    "    \n",
    "    print('Feeding data with shape ', x2.shape)\n",
    "    print('Result : ',sess.run(x_mean, feed_dict={tf_x:x2}))\n",
    "    print(tf_x)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Variables in TensorFlow\n",
    "\n",
    "- __Variables__ are a special type of tensor objects that allow us to __store and update the parameters__ of our models in a TensorFflow session during tarining. \n",
    "\n",
    "### Defining Variables\n",
    "\n",
    "- TensorFlow variables sotre the paramets of a models that can be update during training, for example, the weights in thei inpt, hidden, and output layers of a neural network. \n",
    "\n",
    "TensorFlow provies two ways of defining variables:\n",
    "\n",
    "- tf.Variables({initial-value}, name='variable-name')\n",
    "- tf.get_variables(name, ...)\n",
    "\n",
    "\n",
    "The first one, _ tf.Variable _ , is a __class__ that ___creates an object for a new varibale and adds it to the graph.___ Note that tf.Variable does not have an explicity way to determine _shape_ and _dtype_; the shape and type are set to be the same sas those of the initial values.\n",
    "\n",
    "The second option, tf.get_variable , can be used to __reuse__ and _existing variable with a given name_ (if the name exist in the graph) or create a new one  if the name does not exist. In this case the name becomes cricitcal; that's probably why it has to be places as the first argument to this function. Furthermore, tf.get_variable provides an explicty way to set _shape_ and _dtype_; these paramets are only required when creating anew Variable, not reusing exsting ones.\n",
    "\n",
    "- the advantage of tf.get_variable over tf.Variable is twofold: tf.get_variable allows us to reuse exsting variables it already uses the popular Xavier/Glorot initializaiton scheme by default.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Initializing Variables\n",
    "\n",
    "Here, it is critical to understand that tensors defined as variables are not allocated in memoryt and contain no values until they are initialized. Therefore, before executing any node in the computation graph , we must initialzie the variables that are within .the path  to the node that we want ot execute.\n",
    "\n",
    "The initialization process refers to allocaitong memory fro the assocaitaed tensors and assigning their intial values. TensorFlow provies a function names <bold> tf.global_varaibles_initializer </bold> that returns an operator for initalizing all the variables that exis in a computation graph. then, executing this operato rwill initialize the variables as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w:0' shape=(2, 4) dtype=int64_ref>\n",
      "[[1 2 3 4]\n",
      " [5 6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.Graph()\n",
    "\n",
    "with g1.as_default():\n",
    "    w = tf.Variable(np.array([[1,2,3,4],\n",
    "                             [5,6,7,8]]), name='w')\n",
    "    print(w)\n",
    "\n",
    "with tf.Session(graph=g1) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value w2\n\t [[Node: _retval_w2_0_0 = _Retval[T=DT_INT32, index=0, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](w2)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/VenvPandas/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/VenvPandas/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/VenvPandas/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/VenvPandas/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value w2\n\t [[Node: _retval_w2_0_0 = _Retval[T=DT_INT32, index=0, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](w2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-48d3308c75a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'w2:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/VenvPandas/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/VenvPandas/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/VenvPandas/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/VenvPandas/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value w2\n\t [[Node: _retval_w2_0_0 = _Retval[T=DT_INT32, index=0, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](w2)]]"
     ]
    }
   ],
   "source": [
    "g2 = tf.Graph()\n",
    "\n",
    "with g2.as_default():\n",
    "    w1 = tf.Variable(1, name='w1')\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    ## all the variable declaration must be before tf.global_variables_initializer() in the graph\n",
    "    w2 = tf.Variable(2, name='w2')\n",
    "    \n",
    "with tf.Session(graph=g2) as sess:\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    ##  Throws the error as below  == Attempting to use unitialized values w2\n",
    "    print('w2:', sess.run(w2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Variable Scope\n",
    "\n",
    "Especially useful if we are constructing large neural network graphs.\n",
    "\n",
    "- With Variable scopes, we can organize the variables into separate subparts. __When we create a variable scope, the name of operations and tensors that are created within that scope are prefixed with that scope__, and those scopes can further be nested. For example, if we have two subnetworks, where each subnetwork has several layers, we can define two scopes named _ 'net-A' _ and _ 'net-B' _  respectively, Then each layer will be defined within one of these scopes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'net_A/layer-1/weights:0' shape=(10, 4) dtype=float32_ref>\n",
      "<tf.Variable 'net_A/layer-2/weights:0' shape=(20, 10) dtype=float32_ref>\n",
      "<tf.Variable 'net_B/layer-1/Variable:0' shape=(10, 4) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    with tf.variable_scope('net_A'):\n",
    "        with tf.variable_scope('layer-1'):\n",
    "            w1 = tf.Variable(tf.random_normal(shape= (10,4)), name='weights')\n",
    "        with tf.variable_scope('layer-2'):\n",
    "            w2 = tf.Variable(tf.random_normal(shape= (20,10)), name='weights')\n",
    "    with tf.variable_scope('net_B'):\n",
    "        with tf.variable_scope('layer-1'):\n",
    "            w3 = tf.Variable(tf.random_normal(shape= (10,4), name='weights'))\n",
    "    print(w1)\n",
    "    print(w2)\n",
    "    print(w3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__Note:__ The Variable names are now prefixed with their nested scopes separated by the forward slash(/) symbol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reusing Variables\n",
    "\n",
    "Let's imagine that we're develping a somewhat complex neural network model that has a classifier whose input data comes from more than one source. For example, we'll assume that we have data ($X_A, y_A$) coming from source _ A _ and data ($X_B, y_B$) comes from source _ B _ . \n",
    "\n",
    "In this example, we will desing our graph in such a way that it will use the data from only one source as input tensor to build the network . Then, we can feed the data from the other source to the same classifier.\n",
    "\n",
    "In the following example, we assume the data from source A is fed through placeholder, and __ source B is the output of a generator network which we will build by calling the _ build-generator _  function within the _generator_ scope. __ then we will add a classifier by calling _ build-classifier _  within the _ classifier _ scope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "###############################\n",
    "#    Helper functions         #\n",
    "###############################\n",
    "\n",
    "\n",
    "def build_classifier(data, labels, n_classes=2):\n",
    "    data_shape = data.get_shape().as_list()\n",
    "    weigths = tf.get_variable(name='weights', shape=(data_shape[1], n_classes), dtype=tf.float32)\n",
    "    bias = tf.get_variable(name='bias', initializer = tf.zeros(shape=n_classes))\n",
    "    logits = tf.add(tf.matmul(data, weigths), bias, name='logits')\n",
    "    return logits, tf.nn.softmax(logits)\n",
    "\n",
    "\n",
    "def build_generator(data, n_hidden):\n",
    "    data_shape = data.get_shape().as_list()\n",
    "    w1 = tf.Variable(tf.random_normal(shape = (data_shape[1], n_hidden)), name='w1')\n",
    "    b1 = tf.Variable(tf.zeros(shape = (n_hidden)), name='b1')\n",
    "    hidden = tf.add(tf.matmul(data, w1), b1, name='hidden_pre-activation')\n",
    "    hidden = tf.nn.relu(hidden, 'hidden-activation')\n",
    "    \n",
    "    w2 = tf.Variable(tf.random_normal(shape = (n_hidden, data_shape[1])), name='w2')\n",
    "    b2 = tf.Variable(tf.zeros(shape = (data_shape[1])), name='b2')\n",
    "    output = tf.add(tf.matmul(hidden, w2), b2, name='output')\n",
    "    return output, tf.nn.sigmoid(output)\n",
    "\n",
    "\n",
    "################################\n",
    "#       Build the graph        #\n",
    "################################\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_X = tf.placeholder(shape= (batch_size, 100), dtype=tf.float32, name='tf_X')\n",
    "\n",
    "    ## build the geneartor\n",
    "    with tf.variable_scope('generator'):\n",
    "        gen_out1 = build_generator(data=tf_X, n_hidden=50)    \n",
    "        \n",
    "    ## build the classifier\n",
    "    with tf.variable_scope('classifier') as scope:\n",
    "        ## classifier for the original data\n",
    "        cls_out1 = build_classifier(data = tf_X, labels=tf.ones(shape=batch_size))\n",
    "        \n",
    "        \n",
    "        ## reuse the classifier for generated data\n",
    "        scope.reuse_variables()\n",
    "        cls_out2 = build_classifier(data= gen_out1[1], labels=tf.zeros(shape=batch_size))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__Note__ we have called the _build-classifier_ function two times. <br>\n",
    "\n",
    "The first call causes the building of the network. Then, we call _scope.reuse_variables()_ and call the function again. As a result, the second call does not create new variables;; instead, it resues the same variables. akterbatuvekym we ciykd reuse the variables by specifying the _reuse=True_ parameter, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_X = tf.placeholder(shape=(batch_size,100), dtype=tf.float32, name='tf_X')\n",
    "    \n",
    "    ## build the generator\n",
    "    with tf.variable_scope('generator'):\n",
    "        gen_out1 = build_generator(data=tf_X, n_hidden=50)\n",
    "        \n",
    "    ## build the classifier\n",
    "    with tf.variable_scope('classifier'):\n",
    "        ## classifier for the original data:\n",
    "        cls_out1 = build_classifier(tf_X , labels =tf.ones(shape=batch_size))\n",
    "        \n",
    "    with tf.variable_scope('classifier', reuse=True):\n",
    "        ## reuse the classifier for generated data\n",
    "        cls_out2 = build_classifier(gen_out1[1] , labels =tf.zeros(shape=batch_size))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Building a regression model\n",
    "\n",
    "\n",
    "Since we've explored placeholders and variables, let's build an exampe model for regression analysis. With goal to implement a linear regression model : $ y^{`} = wx + b$\n",
    "\n",
    "For training the model, we need to formulate a cost funciton. Here, we use the __Mean Squared Error (MSE)__ cost funciton that we defined as :\n",
    "\n",
    "\n",
    "<center>$ \\frac{1}{n} \\sum_{i=1}^{n}  =   ( y^{(i)} - y^{`(i)} )^2 $</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf.set_random_seed(123)\n",
    "    \n",
    "    \n",
    "    ## placeholder\n",
    "    tf_X = tf.placeholder(dtype= tf.float32, shape=(None), name='input_X')\n",
    "    tf_y = tf.placeholder(dtype= tf.float32, shape=(None), name='y_X')\n",
    "    \n",
    "    ## Defind the variable(model parameters)\n",
    "    w = tf.Variable(initial_value=tf.random_normal(shape=(1,1), stddev=0.25), name='weight')\n",
    "    b = tf.Variable(initial_value=0.0, name='bias')\n",
    "    \n",
    "    # build the model\n",
    "    y_hat = tf.add(w*tf_X, b, name='y_hat')\n",
    "    \n",
    "    ## compute the cost\n",
    "    cost = tf.reduce_mean(tf.square(tf_y - y_hat), name='cost_def')\n",
    "    \n",
    "    #train the model\n",
    "    optim = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    \n",
    "    train_op = optim.minimize(cost, name='train_operation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a random regression data with one feature (one feature so we can plot it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLoeRvwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f550259a240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_random_data():\n",
    "    X = np.random.uniform(low=-2, high=4, size=200)\n",
    "    y = []\n",
    "    for t in X:\n",
    "        r = np.random.normal(loc=0.0, scale=(0.5 + t*t/3), size=None)\n",
    "        y.append(r)\n",
    "    return X, 1.726*X - 0.84 + np.array(y)\n",
    "\n",
    "x, y = make_random_data()\n",
    "\n",
    "plt.plot(x, y, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cost    0: 17.88\n",
      "Training cost   50: 13.47\n",
      "Training cost  100: 11.70\n",
      "Training cost  150: 10.95\n",
      "Training cost  200: 10.62\n",
      "Training cost  250: 10.45\n",
      "Training cost  300: 10.35\n",
      "Training cost  350: 10.28\n",
      "Training cost  400: 10.23\n",
      "Training cost  450: 10.19\n"
     ]
    }
   ],
   "source": [
    "## Let's traing the model\n",
    "\n",
    "X_train, y_train  = x[:100], y[:100]\n",
    "X_test, y_test  = x[100:], y[100:]\n",
    "\n",
    "n_epochs = 500\n",
    "training_costs = []\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(n_epochs):\n",
    "        c, _ = sess.run([cost, train_op], feed_dict={tf_X: X_train, tf_y: y_train})\n",
    "        training_costs.append(c)\n",
    "        \n",
    "        if epoch%50 == 0:\n",
    "            print('Training cost %4d: %.2f' %(epoch, c) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f54f9f98eb8>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5500234b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Executing objects in a tensorFlow graph using their names\n",
    "\n",
    "Executing variables and operators by their names is very useful in many scenarios. For example, we may develop a model in a seprate module; and thus the variables are not available in a different Python scope accroding ot Python scoping rules. However, iff we have a graph, we can execute the nodes off the graph using their names in the graph.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0  : 17.8812\n",
      "Epoch   50  : 13.4722\n",
      "Epoch  100  : 11.6953\n",
      "Epoch  150  : 10.9524\n",
      "Epoch  200  : 10.6191\n",
      "Epoch  250  : 10.4508\n",
      "Epoch  300  : 10.3517\n",
      "Epoch  350  : 10.2836\n",
      "Epoch  400  : 10.2313\n",
      "Epoch  450  : 10.1883\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 500\n",
    "training_costs = []\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    ## first , run the variables initializser\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    ## train the model for n_epochs\n",
    "    for e in range(n_epochs):\n",
    "        ## executing by Name\n",
    "        c , _ = sess.run(['cost_def:0', 'train_operation'], feed_dict={'input_X:0': X_train, 'y_X:0': y_train})\n",
    "        training_costs.append(c)\n",
    "        \n",
    "        if e%50 == 0:\n",
    "            print('Epoch {:4d}  : {:.4f}'.format(e,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Noote that we are evaluationg the cost by its name, which is 'cost_def:0' and executing the train operator by its name'train_operation'. Also in feed_dict , instead of using tf_X: X_traing , we are using 'input_X:0': X_train\n",
    "\n",
    "> If we pay attention to the __ names of the tensors, __ we will notice that __TensorFlow adds a suffix ':0' __to the name of the tensors.\n",
    "However the __names of operators do not have any suffix __ like that . when a tensor with a given name, such as name='my_tensor', is created, TensorFlow appends ':0' ; so the name of this tensor will be 'my_tensor:0'\n",
    "<br>\n",
    "Then, if we try to create another tensor with the same name in the same graph, TensorFlow will append '\\_1:0' and so on t the namel therefore, the furtuer tensors will be names 'my_tensor_1:0' , 'my_tensor_2:0' and so on. this naming assumes that we are not trying to resue the already created tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Saving and resoring a model in TensorFlow\n",
    "\n",
    "for this purpose , we need to add a new node ot the graph, an instance of _tf.train.Saver_ class, which we call saver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    ## adding the saver call to the regression graph\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next, we can retrain the model with an additional call to __saver.save()__ to save the model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cost    0: 17.88\n",
      "Training cost   50: 13.47\n",
      "Training cost  100: 11.70\n",
      "Training cost  150: 10.95\n",
      "Training cost  200: 10.62\n",
      "Training cost  250: 10.45\n",
      "Training cost  300: 10.35\n",
      "Training cost  350: 10.28\n",
      "Training cost  400: 10.23\n",
      "Training cost  450: 10.19\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    ## train the model for n_epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        c, _ = sess.run([cost, train_op], feed_dict={tf_X: X_train, tf_y: y_train})\n",
    "        training_costs.append(c)\n",
    "        \n",
    "        if epoch%50 == 0:\n",
    "            print('Training cost %4d: %.2f' %(epoch, c) )\n",
    "    saver.save(sess, './trained-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As a result of this new 'save' statement. three files created with extensions .data, .index and .meta. Tensorflow use [Protocol Buffers](https://developers.google.com/protocol-buffers/) , which is a language-agnostic way, for serializing structured data.\n",
    "\n",
    "<br><br>\n",
    "Restoring a trained model requires two steps:\n",
    "\n",
    "1. Rebuild the graph that has the same nodes and names as the saved model.\n",
    "2. Restore the saved variables in a new _tf.Session_ enviornment\n",
    "\n",
    "Note all the of the information regarding the graph is saved as metadata i the file with the .meta extension. Using the follwoing code, we rebuild the graph by imporitng it from the meta file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    new_saver = tf.train.import_meta_graph('./trained-model.meta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The  __ tf.train.import_meta_graph __ function recreates the graph that is saved in the './trained-model.meta' file.  After receateing the graph, we can use the new_saver object ot resotre the parameters of the model in that session and execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./trained-model\n"
     ]
    }
   ],
   "source": [
    "g2 = tf.Graph()\n",
    "\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    new_saver = tf.train.import_meta_graph('./trained-model.meta')\n",
    "    new_saver.restore(sess, './trained-model')\n",
    "    \n",
    "    y_pred  = sess.run('y_hat:0', feed_dict={'input_X:0': X_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note that we evaluateed the $y^`$ tensor by its name that was given previously; 'y_hat:0'.  Also , we need to feed the values of the tf_X placeholder, whih is also done by its name: 'tf_X:0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./trained-model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f55002e5278>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X14XGWZP/DvnTRpm6bpS5KGtmnTAqWd4VVsAXWhILAg\nslT4yV5g6IIi1UtB0XX3WkRduKTL7qXr27LoryArSNRdd+2vLr4AIgUXXUmrgO1M39vQlL6kaUOa\npm9pnt8fd07nzMk5M3Nm5szb+X6uq9c0k5k5Z9Lmnufcz/3cjxhjQEREla+q2CdARESFwYBPRBQS\nDPhERCHBgE9EFBIM+EREIcGAT0QUEgz4REQhwYBPRBQSDPhERCExptgnYNfU1GTmzJlT7NMgIior\na9eu3W+MaU73uJIK+HPmzMGaNWuKfRpERGVFRLoyeRxTOkREIcGAT0QUEgz4REQhwYBPRBQSDPhE\nRCGRlyodEXkCwPUA9hljzhm57wEAdwHoGXnY540xP8/H8YiIylF3N9DZCfT0AM3NwKJFQGtr4Y6f\nrxH+9wBc63L/140xF4z8YbAnotDq7gZWrQIGB4GWFr1dtUrvL5S8BHxjzMsADuTjtYiIKlFnJzB5\nMtDQAFRV6e3kyXp/oQSdw79bRN4QkSdEZErAxyIiKlk9PUB9ffJ99fV6f6EEGfC/DeAMABcA2A3g\nn90eJCLLRGSNiKzpKeQ7JyIqoOZmYGAg+b6BAb2/UAIL+MaYvcaYk8aYYQCPAbjI43ErjDELjTEL\nmwv5zomIHLq7gZUrgRUr9Daf+fVFi4C+PqC/Hxge1tu+Pr2/UAIL+CIy3fbljQDWBXUsIqJcBT2p\n2toKLFkC1NUBe/fq7ZIlha3SyVdZ5g8BXA6gSUS6Afw9gMtF5AIABsAOAB/Lx7GIiIJgn1QFEred\nnfkLyq2thQ3wTnkJ+MaYW13u/m4+XpuIqBB6enRkb1dfr6PxSsGVtkREKI1J1aAx4BMRoTQmVYPG\ngE9EhNKYVA1aSe14RURUTMWeVA0aR/hERCHBgE9EFBIM+EREIcGAT0QUEgz4REQhwSodIgqtYu9A\nVWgc4RNRKJXCDlSFxoBPRKFUCjtQFRoDPhGFUinsQFVoDPhEFEphaJbmxIBPRKEUhmZpTgz4RBRK\nYWiW5sSyTCIKrWyapXV0APffD7z5JjB7NrB8OdDeHsz55RsDPhFRhjo6gGXLtIQTALq69GugPII+\nUzpERBm6//5EsLcMDur95YABn4goQ2++6e/+UsOAT0SUodmz/d1fahjwiYgcOjqAOXN0Be6cOfo1\noBO0dXXJj62r0/vLASdtiYhsMpmYLdcqHTHGFPscTlm4cKFZs2ZNsU+DiEJszhwN8k5tbcCOHYU+\nm8yIyFpjzMJ0j2NKh4jIptwnZlNhwCcisin3idlUGPCJiGzKfWI2FQZ8IiKb9nZgxQrN2Yvo7YoV\n5TMxmwqrdIiIHNrbKyPAO+VlhC8iT4jIPhFZZ7tvqog8LyKbR26n5ONYRESUnXyldL4H4FrHfX8H\n4AVjzDwAL4x8TURERZKXgG+MeRnAAcfdSwA8OfL3JwF8IB/HIiIqBK/VtuUsyBx+izFm98jf9wBo\nCfBYRER5U+5tkL0UpErH6HJe1yW9IrJMRNaIyJqeSt49mIjKRrm3QfYSZMDfKyLTAWDkdp/bg4wx\nK4wxC40xC5srefdgIioblbraNsiA/1MAt4/8/XYAqwI8FhFR3lTqatt8lWX+EMDvAMwXkW4RuRPA\nPwK4WkQ2A7hq5GsiopJXqatt81Wlc6sxZroxpsYY02qM+a4xptcYc6UxZp4x5ipjjLOKh4gob/JZ\nVVOpq2250paIyl4QVTWVuNqWvXSIqOxValVNvnGET0RlL4iqmu5uoLMT6OkBmpuBRYuA1tbsX68U\ncIRPRGUv31U13d3AqlV6ldDSorerVun95YwBn4jKXr6rajo7gcmTgYYGnQRuaNCvOztzP9diYsAn\norKX76qanh6gvj75vvp6vb+cMYdPRBUhn1U1zc3AwICO7C0DA3p/OeMIn4jIYdEioK8P6O8Hhof1\ntq9P7y9nDPhERA6trcCSJToPsHev3i5Zkp8qnWK2XWZKh4jIRWtr/sswi912mSN8IqICKfYCMY7w\niYjyzGvRVrHbLnOET0SUhe5uYOVKLf9cuTKxKCvVoi2vhWCNjYVZ1MWAT0TkU6qgnmrRltsCsZoa\n4OabC7OSlykdIkqrWH1lSrWfjT2oA4lb61xbHDt419drtY81QXvvvcD+/fqeli4FLr9cSz87O4N9\nfwz4RJSSNZqdPFkD2cCAfp2vMsVSO24mUgX1dIu22tuBw4f1+VVVo58fJKZ0iCilYvWVyfS4xahr\nt4K6nRXUM1m0ler5QWLAJ6KUitVXJpPjWnXtXV2AMYm69qCDfqqgnsmirWKt5BVjTLBH8GHhwoVm\nzZo1xT4NotDq6NCa8Dff1IoSa5JxcDA5RdHfr/ffeGP618w2D79yZfrjzpmjQd6prQ3YsSP9MXKR\n6/xCPucnRGStMWZh2scx4BMRMHoVKKDB9eGHgepqTafU12vqoa8vs1y6PQ8fxHOrqnRk7ySiI+ew\nyDTgM6VDRAC8V4F+7WvuKYqXXkqfO88l/59JaiTfG59UOlbpEBGA1KtArb4yHR3AZz6jaRSRxOja\nqydMqmqWTKTrZ7N8uftVSbYbn1Q6jvCJCID3qHjqVB3Bi2jNuJUzd6ZS3HrC+KlGyabaJt8bn1Q6\nBnwiAuC9CvTQIe8g79TVlRysM61GyaXapr1dJ2iHh/WWwd4bAz4RAXAfLTc0AMeP+3sde7DOtK98\nsbtIhgWrdIjIk1cVTCb8lEay2iY3rNIhopylq3YR8f6en5a/ha62KeauU8XEgE9Entzy+laQb2sD\nvv99vXXjJ1i7HcdvtU2mQbxYq3NLgjGmZP68853vNERUWp5+2pi2NmNE9Pbpp0d/v67OGA2f+qeu\nbvTjcj1Ouudmeg5tbcmPs/60tfk731ICYI3JIMYGnsMXkR0ADgE4CWDIpMgzMYdPVJ7cWjIUslrG\nT4uFSpwvyDSHX6iFV1cYY/YX6FhEVGDt7cUth/SzdeDs2e4fDmFYncscPlGZCuvEoxs/k775mC8o\nV4UI+AbAcyKyVkSWFeB4RBUv1BOPLvwE8TCvzi1EDn+mMWaXiEwD8DyAe4wxL9u+vwzAMgCYPXv2\nO7vcrrWIKEkx2wKXqkLNI5Titosl2R5ZRB4AMGCM+arb9zlpS5SZSpx4LAe5tHsOUkksvBKRCSIy\n0fo7gD8HsC7IYxKFQbHbAnd36wYlK1bobXd3OOYUirXdY74EncNvAfA/IvI6gFcB/MwY88uAj0lU\n8Yo58WiNcgcHtfXx4CDwhS8AH/1o8pzChz8MNDVV1gdAsbZ7zJdAyzKNMdsAnB/kMYjCyMpNF6P2\n3T7KBfT2mWeAo0eTH3fiBNDbq3/36pdfbqx2z/ZtFwux+Xi+sCyTqEwVqy2w2yjXCuyplHL3S7cU\nlZu8bz4+PAzs2pX1efvFHa+ISpyfqpBCVKq4jXIbGzML+n4aquWL8+e3c6du22j9jD772cSevS0t\n+t5WrXKfiLXaPXd2arvn5mZg8eIMJmyHhoCtW4F4HIjFErcbNmj/6cOHgdrawH4GFrZHJiphfqpC\nvDYhz0eNuT1oVlUBe/YAc+cmzun554F///fRaR2npibgj38sXEWL8+f37LPA449ruslSWwvceSfw\nvvcl7uvv15/djTf6PODRo8CmTYmgbgX2zZtTbyywfj0Qjfo8WEKptVYgIviv4XbLl1v3+9lExBnw\nU10JOM+xtRV49dXkEbCIvvbhw/qYhx4Crr468ZpTp+pOWfYYV1MD3Hyz++g5m9r2TK5mnD+///zP\n5GAP6Dn++MfJAT/tvruHDiUHdOvv27b5r4ttagL27csp4GeKAZ+oQOyjzXSpA4ufTcAz7SfjvBKw\nT6guXjz6HB97DDjnnOQPnYkTgS1bgDPOSLxue7s+3wrcsRjw1FPAwYMaxJcuBS6/XEfP9g+sbH4u\nqd5Dqk3Uvapp9js6fZ2aiO3tHT1aj8c1L+TXzJka1CORxG0kUtAZXwZ8ogLxM1q3+KkKybQpWKor\nga9/ffQ5Dg0Bb72lKRxAg+P69TpSfve7EwH6oouSrwQmTNAPpquuAqZNSxzL+YHl9nPp7QX+5V/0\nA8VtxO/1Hj796eSA7/z5NTe7BX2D6KS3UPfbOKbtj2Hs9jgmdMVw2sE40Ouz3lIEOP300UF9wQJg\n0iR/rxUABnyiAvEzWrcsWqTB1HqslcNfvHj0Y5cvd8/hO2vzU10JuJ1jS4tmHCybN+skZ2NjYvER\noOmS885LDtwtLcCf/gRceWXi+c4PLOcxrQ+UoaHkDxT7iN/rPfT26ujfCvpJP7/xJ/Hxq3fgjX+P\nY97JOKKIIYI4Iohj0tv9wD+6v6armhpg3rzRI/azzgLGj/fxQoXFgE9UINnUcPupCsm0Nj/VlYDb\nOU6froG0vz/xATVmjMY7S329Vhe++93Jr3nuucALLySe6/aB5Tym1weK/UrI6z0AwAOfP472d2wB\nYjG0xuP48No4jr8eQ/2ujVhyIs2sstP48To6t4/Wo1G99Kip8fdaJYABn6hA/IzW7VpbM69qyaQv\nfaorAbdzrK4G7rpLc+179+oc48yZwLp1usVhT48G50suGf1hMW4ccMUV+vpeH1jOY+7ZkxhAW5xX\nQsuXA3fdNoj52IgIEqP1KGI4880twNlDifc28ielSZPc8+ttbfqpUyFYlklUQKmqUQq5a5SfKh1n\n/ry7W1sp/OAHo8sbb71Vq3UyKSG1H/+znwVmzdJjbt2qHyjWnMGYgT5UbYyjeX8cF45PTJwOb9+B\nKviMXy0tyUHduj3ttNQ7spe4kuyWmQ4DPoVVkDX0QZg5UydynWbMAB55JHV5pet7HW/w1Ff34f9E\n4zj4Sgw7n9MJ1Mm74xh3cLf/E5w92z2wT53q/7XKAAM+URkpt/72WbdnNgbvnrUTE3clp2EiiKMR\nB3yfRP+0M/G/b0fwhyMR7G2M4s8/HcH7PrMA3X31JdezPkhceEVURvzsyVoK0paADg0B27cntxGI\nx4ENG/DbgQF/B6utBebPHz1xOm8eGsaOxZ9D+65bsqnrDwsGfKIs5HvXo3LbWNua+B0aPIazsAkR\nxHH+mBhuOy0OnBvT9gKpWgm4OCwTMOGdLmmYuXO1LChD2ax3SKeQ8ytBYsAn8imIEeTy5dpP3t6L\nZty47Pvb5z1ADQxoo6+RkXp7LIa/aIhjwuBWVGMkhzME4PfpX+pY/VSsHYxg3XAUcUQQQxQ7xkXw\npRWtaF+ae0VMNusdUsl0VW85YMAn8imIEeTixXqV8JvfJO6bO1fX8fiVU4A6cGB0R8d43DW31ODy\ndLsjU2egb3oEPY0RzLomiinv1lH72OZmbP+B4B8CGjHnu2e9nx5FpY6TtkQ+rVihI0h7efbwsI4g\nrcDq1733anXLyZOJ+6qqgMsu01r3l17KfMSedgLYGGD37tGNv2Kx5CW1GRiGYAfmIIboyJrVCHY1\nRHHv/41gaIK2Esi682SW8r3vbDnsH8xJW6KA5GME6ZwD+N73koM9oMGksxP46le1gZl9xL50KfDK\nK8CjjyY/p6MjEewFw2hD16kqmLO7YuiZF8fYrXE0mLf9vekxY4Azz0yaOL3wtig2YD6OOJc19QN3\nT0h8mUs6JRtZ96z3UG7zK6kw4BPZZJL7znbFrMVtDuBtj/h7+LCO8J0pBWOAb38bOHYM+ItrT+CS\n5q3Y9P9i2PxoHN8fKXVcgA2ow5HkJ25Jc3LjxmkrAeeK0zPPHLVBx4H7gSMugbCxMflrrw/DICdC\n/axOTifTHkXlgAGfaMS3vgX8zd8kiku8ct+5jiDd5gAmT9YPDafJkzWtDgDjcGRUK4Fznoxj3pOb\nUX3yBE4DcFmG7/VtNJyaMN0zOYLPPx1NtBKors7oNa67DvjOd5LTHePGAddfn7p3DlBeE6HF3D84\n35jDp1ByW9r/wAPau90p1eKnzk7tErlrl64+/eAH0+9v6jYH8OKLwDe+ocFzIvoRQRznVsVwUySO\n2i0xzD0Wx1xs991KYB+aEUcEM94bwSO/jmI9ooghit2YDkBbCWSTi3ZbLSsCfPzjwOc/n75ktdwW\nmpU6rrQl8uAWrGprvcvGvQJiZydwzz3aROzwYe3/fs452sc9VdBfuVKP3WR6UL8zjok7Y6jdGofE\nY2jYFcf0Yf+bWg82zcL/9kXwxlDk1Mg9jgh60XQqiOYjyFpzDx/9aOLKI5vXSjcRmu91DpWOk7ZE\nHtzK7I4f12DjFoQaGzUAOQPOgw9qULI+DA4f1q8ffBB45pmRBxmjT7ZVwlz3WhzDsTjGDzi2WUrj\nJKqwDaefCuabqyM49y8jOGtJBAeHJqKzM3lyF0jONWeSi07XVM2ae3AL9kDmK4NTTYRypWxwGPCp\nomQyMvQKSsaMHulXVXnvw/rii4lgX4WTmIvtiA7HcP5zceCOkTLHDRt0/1ObseneRE2NFuDbV5xG\no/iPNfNw34Pj0NWlVxMA8MQPgcbnNG/+0EP6fr0CdrpcdLq8un3uwX3nKH3NTCZjU334BLHOgRRT\nOlQxMq2/9kptTJkC3HKLVsUMDGhQ/dCHgHe9C3j9dV0Fe+17j+OSxs047UAMX/rLxOTpfGzEOBzz\nd8ITJozeXCMS0c01UrQS6OgAPvKR5A+m2lrgiSeSA6vfKph0KR/73MPq1bpuwH4OdXXA7bcDTz6Z\nWddPr/MLYp1DumMGpVDHYw6fQsfKjdvr452Lfrq7ta790UeTe7nX1QE33QT88pe6xV5L/WHcffVG\nXNoUw+CaOGb2xzCtN45p/VtQNewomE/jAKacWpQUQxTbxkZxxz9F8IF7ZmW1uUaq1sS7RtL/2bRb\nTpdXd/58V6/W4N7bqx8Ky5drcPP60Pif/8ksL5/Jv2M2Ct2CupDHY8Cn0HGODFevBp56SgN4W5tW\n4lRX6xXA2rX6vZO9B3FZUxw3nx3DgVfiOHNIR+1z4LF/Xgq7cRo2SBQzropg2mXaK+aur0exsW8a\nrIoYSy7VKKn26bCmDN7xDn3fTqmOm26En8kVlNeHBqBXBJmsfs33StlM31++FfJ4nLSlipTqEtm+\nAjY55WBwtGsvfvbXMXz4XXFcPDGGa3bG8Q8nYxiHvcB+AC9lfg5vVrUlNf6yRu+HqqfgySeBeYuB\nH4wErI0utfVAbm2Pp051nzSdOjURLN2CfbrjuuXVRbTeHshs/YHXZGxTU+Z5+XyvlLUUugV1Kba8\nZsCnsuCWinFOKi565zB+/eRODO+Kofbf4njkeCLHPhUHtZvjbzwPkWQI1diCMxFHBBMWRTH2gggk\nGsXAzPl4/19OcH2ODOt5rFyZ2eRmtpYuHZ2SqqnR+60Jz2yO296u7Rrsi6mM0bTNe96j30+3gtVr\nMvaGG3S0bpeq5UI+V8paCt0ioRRbMlREwK+UXtXkzhq1Pv20BrlqDOEMbNUVp4MxjP9YHPh6HK3x\nOP5qJNIsyfC1T9aMxaGZC/Dyvgg6BxOj9c2YhxOoxYwZwOdvT04vTJnivkDL+kW2t+ddutR9cjOX\nZfmf+5ymOJ55RvPnjY1apfO5zwE//7keO9vj/vzno1MyfjpDelUC1dXpz+4Pf0je+Py22/y991wU\nukVCKbZkCDyHLyLXAvgmgGoAjxtj/tHrsdnk8MttL1Dy4ehRYNMmvPpkDOO2x7FxpY7Wz8Im1OJE\n+ufbHEI94ohga20EC26M4tgZUextjGJXzRzccGM1XnrJ+//R4sXJk407dwL33ef9fy6Tyc1U/zcz\nKS31eoz92KtXJ4JrU5Ou5E33OxFUZ0ivjc/HjQMef7xwv6us0gkw4ItINYBNAK4G0A2gE8CtxpiY\n2+OzCfilukSbVx2jeQayQ4eSNtc4dbttm+8o04MmbJAIDrVG8cJbEfzppObZd2Em6uoEDz8MzJoF\nbNyoo/SpU7XkvbUV+OIXgeee04BntQlwdqO0ZLpAye+kY64Tlrk+P8jfJ6/qomL/rlaCUgn47wLw\ngDHmmpGv7wMAY8zDbo/PJuCXSq9qewCYOlXLyJxlf2G+6ujuBp7t2I9ZA3FM641j3LYY6rrimPF2\nDGN2d/t/PcxEDFFsQATrbROn+6FtGZubNa3hNsJ1BsWuLh15rlmT3KI4l9Fntq0B8lGSmEtbgiCv\nmAv9uxqm9gylUqUzE8BO29fdAC62P0BElgFYBgCzs5jNKIWJEecvSW/v6MeU6w45Tl6/RKfu32cw\nq/otLKyLoXm/thM49scYJv8pjjsHXWYRUxHBjurT8cZQNKmOfQMW4BAaMGOG+4gR0PO77DLgwgtH\nj3CdKzn37NF+OM5+9EePAn/7t9n9m2U76ZiP7flymfAMsjNkIX9Xy6k9QyGzAUWftDXGrACwAtAR\nvt/nl8LEiFtvFjfFLMfKh6RfouZhYMcOvPZsDKY2joFXY7h0fxyTdsdRM9if9LyxSN1O4GTVGGw0\nZyFmNKBbe5ze++hZ+NCd4z37Q/7+98AFF7h/wAI6ar/lltElfc6g+vbb2gfHzVtvuffRCUq+t+fL\nRnt7MAGnkL+r5dKeodBtooMO+LsAzLJ93TpyX96UQq9qPw2j8qkgl6zHjwNbtgDxOPr/K47374hh\nyp446ndtQPXxo+mfb3+pMePR0xTBzvoINiCCY2dEMTArgq/85AzsPVCT/OCjwN896D0qbGzU957K\nypVaTuhMhTiD6qRJ2uXALehbxylUkNi5M9GmualJ+/icfXbmm6uUskL+ruZ7I/OgFHq/3KBz+GOg\nk7ZXQgN9J4APGWPWuz2+XFfaek102eU7h5/31YiDgzqT6dzjdMsWYGjI10sdxGRskAhOzIui5rwI\nsCCC7oYofr1lNurqq7Bjh/5CRqPAxRdrXxg3IpqD//CHk+dDamuBT35S29B8/OPeKzsBDZrOenSv\nHP7vf5/8uJoa4O679TjXXRf8h6tX2+avfAX41Kfye6xKF1R7hnzL17xGSeTwjTFDInI3gGehZZlP\neAX7QgliVOx2qVpbC0ycqCsigxjJZH3J2teXHNCt266u1JHTxR60YFN1BOuHo1hvEjn2PTgNMAJs\nApoOADc3A4tOB6q7gPXrE73ZL75YA7LXIiGrRcInPqE1+L29icnYCy/UX16vKwCL24pT50rOWbO0\nh/2DD2op4+HDOvF+xx16nCNHCpMP9mrb/LWvMeD7les2lNnIJhdf6DnIUPXSCapHB1D4MsyUHQXv\nMhpBnaP1WAzYvdv/wWbPBqJRHGqN4D/XR/C9V6P408kIDmJqRk+vrtbA2dKiwXP3bg34H/ygBvzV\nqzXg2kfxlro64OGHEz1wnP9ubvXzdm4jfC9e/z9qa/U8gh4tlkrFWaUoZJVOttVN+aqKKomyTL+C\nDviFvswL8kNg5Upg8LBBy/GdiV2TtsUxZU8cTXtj3jtUeKmq0o2qrRa9VsveBQuS1sR71VKnU1Oj\no6tJkzSAbtumuekbbtDA+vzz2szM7b9juk6LHR2aenHuCVtTo+0Y/IyO3YKEtXo1iHa9dqW6poTS\ny+XfLh9xggHfRZB9tp3yWs88NARs356Ugjn+ehzYuAG1xwZ8vZSprUVv03wMzI7i6JwIepqj6J4Y\nwaUfmYfWM9xraez/IXP57/KFLyT+vnu3BtebbkoE1tmzcxvhfutbwJe/rGmcpiZdSJWPVEihBgpc\nNV6+in11VhI5/FJTyJK3rGbfjx0DNm8eveJ048ZRG67WpjuBCROSR+ojf1/1+lwcPjYm6Wcw3A90\nvgG0njH6ZdyCUDacjbMaGnRUZP+gzTWf+alPBZPrLlQ+uBQqzsIq11F2KawHykSoAn4hJ3K8JhK7\nugAMDOAXX9+A574ZR0tvDBeOj+OSSTE09GwbvfonnalTk7fCs4L7rFmujdP3vZh5uVpHh06Q5noR\nWFWlx3z9db3Era3VCdhLL01+XD7rtPOZTguqXa+boGrgyVs+auFLYT1QJkKV0gEKN5EzZgww6WTv\nyPrQRJveCOJoQxYrsKZPByIRHGo7G1trItg5MYqqsyM4/6pmtM5KsSOGg59doR55xP/nj9OUKcD7\n36+Xtfv366TtvHnA6afrdnjOn326QJ3Jvx9TI+RHvuZOitk/izn8QjFG1+Y70jB7V8fQgn2+XmoY\ngkONc1B7fgTjL7SN2hcsACZPzkuVUbrX6OwEHntM69K9Vp8Cia6PqdI9Vh19Q4MG+82bdYTc1ATc\nc4//D9pc96zl5Ce5KXb+PR+Yw8+34WGNIs4a9nh8dHkIgBaXl7CcwBhsxryk/jBxRLAR8/HYN+s8\nJwP91t57jYa90hPd3Rrsx4xJHexrapJHL149zY1J5O6bmvSPNUmezVVVpu+/FHcaotJVLvn3fGDA\ndzpx4lQrgaTAvmGD5iN8OIJx2IAFpwL6ttoIbv1yFJ/51zOx9c2aUY9vbk69/NvPcvF0zaPcAm5n\npxYENTdrMO3vH/0YEV0IZQX79nbvjaubmvI7SZ7p+w/TLzDlziv/ft11erVYSRPo4Q34R45o9Ytz\nxenmzb5bCaChIXnSdOT2J6/Mwac/U3WquVfjROD9M4EH/8F9Ze7SpRoQYzENlqee1wh86UvArl26\n/L+lRfPgVkB1C6DWaHjvXuAnP9Ha+ePHgV/9Cvirv3LPfVsB9ehR4IorgP/+7+RL2poa4EMf0p2V\n7Lx+Yb74xcTFTz4myTOtsiqXCTQqDW7VUdddp5vWFKqpWaFUfg6/v9+9lcD27b7LT042NqP67JGA\nbq+ImTHDtSKmo0P7xNgrKmtrgSee0GD+93+vAXDCBODWW4HLL9cFSB0doz9zqqqAD3xA9wo5dgwY\nO1YbgzU1uefwV6zQt75qlaZo+vp0AnZwUD9Y3J63cqU274rF9Jy2bNEPiMFBXTB1xx0a7N2uDrwm\nrPI5Se5nDoMb0FAuym0eKHyTtm6tBOJxHRb7NWsWjs6NYGNVBEdPj+L4mVHsmRLBvpONviZI7aN0\nu8mTgYetB+NZAAAOSElEQVQe0r4yP/yhBq3x4zXo//KX3itZx44Frr1WR+3792vgP3xYOyvag1pH\nB3DvvfqYsWP1eAcP6gfPmDHaUvjee0cvHLIC6smTujBq7159/F13aaAuBWHa1IKKp9wmcsMzabt2\nLXDNNd5N0b1UVWltoGNhEhYsACZOxC8c5YvjAEzu99cq1+uU+vo02H/3u4nR/5Ej2iDMsb4qybFj\nwKZNWmJ/8mRye2DrkvOVV5IvRY8dS85xDw3pj2ztWn2rdvYJ3XHjgIsuKr2AmsvmHkSZqtR5oPIP\n+DNmpA72NTW6aakzsJ91lkY1D24ThEePak+XfIwuf/zj0cH9+HFtEuZV+15To1cCAwO6iMlpcFBT\nOelq543RvjWPPTb6ewyoRJU7D1T+Af+00zTBPDSkQ1Z7YI9EgDPO0LyET84Jwv37gd/8xl+L3MZG\n98+isWPd2/YCGqxra91H+tOm6XOt9IzX8zPR26vnvXIl0yNETpXa5qIq/UNKnIhW2/T36y7UTz0F\n3HefznDOn59VsAc0+PX16csOD+uI2hjg/PM1G9TQoME/1a5L3/ymjsrtqqqAhSkybW1tOqnb2Ji4\nb+JEze83NWkTTOtDwU11dWbvb9o04NVXdQTT0qK3q1ZpjpyINLjv2KG//zt2lH+wByoh4AOjW2Bm\noLtbR7crVuitM9BZ+ey6Os2BHz2qm2I3NSUeU1+futd6ezvwb/+WeE5zs043eH1IWJeM7e16BbBz\np3Z//MhH9MNl/nw95sSJwHnnjX7LNTV6GVpXl/q9i+gHiLWIKdMPMCIqb+Wf0slCpjva2/PZVg8a\nu0wWEbW3ayWN9Zl0553u6ZjqavdeL/Zqz+nT9QpgYEAnY6dP1zmFgwe1jFIE+M53tJ/a+PHeUxvG\naObL2cGyFPf8JKL8CWXAdy7RP35c11s99JCOwJ257O5uDZ4vvKCB+9xzdb431SIiex14Y6NuRv2+\n93lfEQwPjw72nZ1aD3zeeYn7+vv1g+f4cX0Pd94JPPss8PjjiR2jent1lO81h9DWVthW0URUGioj\npeNTT09idLt/v65eFdERuDOXbV0NjB8PXHWV3vfCC/o4rwlbq1ujtU3s/v0akH/xi+SUkJ1buZf9\nPC319fqa9nTTj388entA62rEmd6x0kbOOYr+fv26VOrtiSj/QhnwrdEtoCP7CRM02Fujfnsu2341\nMG0acOWV2u63qcm7osVt85MTJzQw33DD6AlXr3Iv+3larFF4a6sumlq2zDt1c+CApona2vQDra0t\nkTZyzlHU1eV/U24iKi2hTOnYN0Lp69P0zOAgcM45ep89l+2nYZnFqytjb68utnrve0eXey1ePLpE\nMtMNW1ItEkm1oQZr7onCpWJH+B0dmv+uqtLbjo7E9+yjW2M0pXHxxfq93/1Og+zWrZrOcRtld3Xp\n970qfLxW41n3O8u9Fi/WYzpLJIHMRuHLl3unboiILJXTS8fGz45H3d3aimD7di3nr6vTdM3FF2vl\nzEUXab261bCrq0vbF7znPYmKGWcDL787LuVjk2w2CyMKr/D00nHhdwNxa9OqsWP1jwiwbp22Fe7t\n1e4NN9+spYy7dmmwnztXn+u2CYffVXrZpI2cuBcqEaVTkQHfz45HnZ0avHfv1lF8VZUu2P3RjxJt\nCt56S/vOrFihnRoyCc5+AjBLJImoECoyh58uh25nlT5OmqSraQFN2Th70lhXCKkqZ9Kt3vXCEkki\nKoSKDPh+JjGtAD5vnq6IHRzUTUbcvPmmd3BubXWfeM0k6LNEkogKoSJTOn5y6Dt3Ag88oO0JGho0\nvVNTM3ohE6Cv47UJuN8Nxp1YIklEQavIKp1MuVXTVFUBl14K/Pa3yUE/VZUNoN9z9nB78UWtAHLu\nSEVElE+ZVukEltIRkQdEZJeIvDby57qgjuUlXU7drZpneFh3R7znnkSLYvsKVS/O3P7q1cAjj+hq\nV2MSO1LZ1wMQERVSYCN8EXkAwIAx5quZPiefI/xMNrz22rcSAH76Uw3+e/cmdqv3c7w77/RuXFaK\nmyATUfkq+gi/2Ow5da9+717VPFY5pJ/SSOfEq1d/G6+SUSKioAUd8O8WkTdE5AkRmRLwsZJ4dZq0\ntyd2q+apqQFuu81/aWR3t36YWL1wZsxwf1y5b4JMROUrp4AvIr8SkXUuf5YA+DaAMwBcAGA3gH/2\neI1lIrJGRNb0pNo+yqdU9fKW9vbkbpIzZgCf+IRujeunNNJK59hLMq++evQe6exvQ0TFlFPAN8Zc\nZYw5x+XPKmPMXmPMSWPMMIDHAFzk8RorjDELjTELm/O4tDTTxUz2Rma7dgHf+EaicufP/sy9+ZqT\nW/ro6quBj33MvTUxERVXquaKlSywOnwRmW6M2T3y5Y0A1gV1LDde9fKZjNid5ZpWhQ3gHrC9euFE\no/oBQkSlw+/vdyUJskrn+9B0jgGwA8DHbB8Argpdh+9lzhz3/vJeFTb56HZJRIXh9/e7HBS9W6Yx\nZmlQrx00P83XgMw3KiGi4vP7+11JKqosM9e8nLVQa4pHPZFXhQ174RCVDz/NFStNxQR858bhXV3A\n0qU6YZpJ8LdX2tx+u5Zn2qWrsLHvMXvjjQz2RKUqzDvEVUzAd2uTYE1PZNLWwF5pc8UV/lsrEFF5\ncJZjh+n3u2Kap6Vqk2BJNSnj1vzMT2sFIqJiKfqkbaHNnu0+827X1aU5ems17KJFidQLd50iokpX\nMSkdt7yc05Qp3huUcNcpIqp0FRPw7Xk5QHNzdrW1wC23eDdTY6UNEVW6iknpAMkbh3d0JO94deWV\nwDXXJD/eufk4d50iokpWMSN8J3uPnB07gOuvT99MjYioklVswHdijp6Iwi40AZ85eiIKu4rK4afD\nHD0RhVloRvhERGHHgE9EFBIM+EREIcGAT0QUEgz4REQhwYBPRDSi0jc3D1VZJhGRlzBsbs4RPhER\n3DdRGhzU+ysFAz4REcKxuTkDPhERwrG5OQM+ERHCsbk5Az4REcKxuTmrdIiIRtg3UapEHOETEYUE\nAz4RUUgw4BMRhQQDPhFRERSjjUNOAV9EbhaR9SIyLCILHd+7T0S2iMhGEbkmt9MkIqocVhuHri7A\nmEQbh6CDfq4j/HUAbgLwsv1OEYkCuAXA2QCuBfCoiFTneCwioopQrDYOOQV8Y0zcGLPR5VtLAPzI\nGHPMGLMdwBYAF+VyLCKiSlGsNg5B5fBnAthp+7p75D4iotArVhuHtAFfRH4lIutc/izJxwmIyDIR\nWSMia3p6evLxkkREJa1YbRzSrrQ1xlyVxevuAjDL9nXryH1ur78CwAoAWLhwocniWEREZcVazXv/\n/ZrGmT1bg33Qq3yDaq3wUwA/EJGvAZgBYB6AVwM6FhFR2SlGG4ecAr6I3AjgXwA0A/iZiLxmjLnG\nGLNeRP4DQAzAEIBPGmNO5n66RESVo7sb6OwEenqA5mZg0SKgtTW444kxpZNFWbhwoVmzZk2xT4OI\nKHDd3cCqVcDkyUB9PTAwAPT1AUuW+A/6IrLWGLMw3eO40paIqAg6OzXYNzToatuGBv26szO4YzLg\nExEVQU+Pjuzt6uv1/qAw4BMRFUFzs6Zx7AYG9P6gMOATERXBokWas+/vB4aH9bavT+8PCgM+EVER\ntLbqBG1dHbB3r95mM2HrB7c4JCIqktbWYAO8E0f4REQhwYBPRBQSDPhERCHBgE9EFBIM+EREIVFS\nvXREpAdAV5ZPbwKwP4+nU2yV9H74XkpTJb0XoLLej9/30maMSbtkq6QCfi5EZE0mzYPKRSW9H76X\n0lRJ7wWorPcT1HthSoeIKCQY8ImIQqKSAv6KYp9AnlXS++F7KU2V9F6Ayno/gbyXisnhExFRapU0\nwiciohQqKuCLyFdEZIOIvCEiK0VkcrHPKVsicrOIrBeRYREpy8oDEblWRDaKyBYR+btin08uROQJ\nEdknIuuKfS65EpFZIvKiiMRG/o99utjnlC0RGScir4rI6yPv5cFin1OuRKRaRP4oIs/k+7UrKuAD\neB7AOcaY8wBsAnBfkc8nF+sA3ATg5WKfSDZEpBrAvwJ4H4AogFtFJFrcs8rJ9wBcW+yTyJMhAH9t\njIkCuATAJ8v43+YYgPcaY84HcAGAa0XkkiKfU64+DSAexAtXVMA3xjxnjBka+fJ/ARSw8Wh+GWPi\nxpiNxT6PHFwEYIsxZpsx5jiAHwFYUuRzypox5mUAB4p9HvlgjNltjPnDyN8PQYPLzOKeVXaMsvaN\nqhn5U7YTkyLSCuD9AB4P4vUrKuA7fATAL4p9EiE2E8BO29fdKNOgUslEZA6AdwD4fXHPJHsjKZDX\nAOwD8LwxpmzfC4BvAPhbAMNBvHjZbYAiIr8CcJrLt+43xqwaecz90MvWjkKem1+ZvBeioIhIPYD/\nAnCvMaa/2OeTLWPMSQAXjMzZrRSRc4wxZTfXIiLXA9hnjFkrIpcHcYyyC/jGmKtSfV9E7gBwPYAr\nTYnXnKZ7L2VuF4BZtq9bR+6jEiAiNdBg32GM+UmxzycfjDF9IvIidK6l7AI+gPcAuEFErgMwDkCD\niDxtjLktXweoqJSOiFwLvRy6wRgzWOzzCblOAPNEZK6I1AK4BcBPi3xOBEBEBMB3AcSNMV8r9vnk\nQkSarWo8ERkP4GoAG4p7VtkxxtxnjGk1xsyB/r78Op/BHqiwgA/gEQATATwvIq+JyHeKfULZEpEb\nRaQbwLsA/ExEni32OfkxMnl+N4BnoZOC/2GMWV/cs8qeiPwQwO8AzBeRbhG5s9jnlIP3AFgK4L0j\nvyevjYwqy9F0AC+KyBvQQcbzxpi8lzNWCq60JSIKiUob4RMRkQcGfCKikGDAJyIKCQZ8IqKQYMAn\nIgoJBnwiopBgwCciCgkGfCKikPj/k1OMZ2MGdmMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f55099a6d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Let's visualize the predicitions\n",
    "\n",
    "x_arr = np.arange(-2,4,0.1)\n",
    "\n",
    "g2 = tf.Graph()\n",
    "\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    new_saver = tf.train.import_meta_graph('./trained-model.meta')\n",
    "    new_saver.restore(sess, './trained-model')\n",
    "    \n",
    "    y_pred  = sess.run('y_hat:0', feed_dict={'input_X:0': x_arr})\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(X_train, y_train, 'bo')\n",
    "plt.plot(X_test, y_test, 'bo', alpha=0.3)\n",
    "plt.plot(x_arr, y_pred.T[:,0], '-r', lw=3)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__Saving and restoring a model__ is very often used during the traiing stage of large models as well. Since the training stage of large models can take several hours to days, we can break the training phase inot smaller tasks. For example, if the intended number of epochs is 100 we can break it inot 25 task, where each task would run four epochs one after the other. For this purpose, we can save the trained model and restore it in the next task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Transforming Tensors as multidimensional data arrays\n",
    "\n",
    "- We explore a selection of operators that can be used to transofrm tensors. Note that some of these operators work very similar to NumPy array transformations. However, when we are dealing with tensors with ranks higher than 2, we need to be careful in using such transformations, for example, the transpose off a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In NumPy, we can use the attribute arr.shape to get the shape of a NumPy array. In TensorFlow, we use the tf.get_shape function instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"T1:0\", shape=(3, 4), dtype=float64)\n",
      "Shape of T1 is  (3, 4)\n",
      "<tf.Variable 'Variable:0' shape=(3, 4) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_1:0' shape=(3,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    arr = np.array([[1., 2., 3., 3.5],\n",
    "                   [4., 5., 6., 6.5],\n",
    "                   [7., 8., 9., 9.5]])\n",
    "    T1 = tf.constant(arr, name='T1')\n",
    "    print(T1)\n",
    "    s = T1.get_shape()\n",
    "    print('Shape of T1 is ', s)\n",
    "    \n",
    "    T2 = tf.Variable(tf.random_normal(shape=s))\n",
    "    print(T2)\n",
    "    \n",
    "    T3 = tf.Variable(tf.random_normal(shape=(s.as_list()[0], )))\n",
    "    print(T3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Notice that we used s to create T2, but we cannot slice or index s for createing T3. Therefore, we convereted s into a regular Python list by s.as_list() and then used the usual indexing conventions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__Reshape__ In Numpy, we can use np.reshape or arr.reshpae for this purpose. In TensorFflow, we use the function tf.reshape to reshape a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(1, 1, 12), dtype=float64)\n",
      "Tensor(\"Reshape_1:0\", shape=(1, 3, 4), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    T4 = tf.reshape(T1, shape= [1, 1, -1])\n",
    "    print(T4)\n",
    "    \n",
    "    T5 = tf.reshape(T1, shape=[1,3, -1])\n",
    "    print(T5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.   2.   3.   3.5  4.   5.   6.   6.5  7.   8.   9.   9.5]]]\n",
      "\n",
      "[[[ 1.   2.   3.   3.5]\n",
      "  [ 4.   5.   6.   6.5]\n",
      "  [ 7.   8.   9.   9.5]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    print(sess.run(T4))\n",
    "    print()\n",
    "    print(sess.run(T5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__Transpose:__ In Numpy : arr.T, arr.transpose() and np.transpose(arr). In TensorFlow , we use the tf.transpose funciton instead, and in addition to a regular transpose operation, we can change the order of dimensions in any way we want by specifying the oper in perm=[...],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"T6:0\", shape=(4, 3, 1), dtype=float64)\n",
      "Tensor(\"T7:0\", shape=(1, 4, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    T6 = tf.transpose(T5, perm=[2,1,0], name='T6')\n",
    "    print(T6)\n",
    "    \n",
    "    T7 = tf.transpose(T5, perm=[0,2,1], name='T7')\n",
    "    print(T7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__Split __ Next, we can also split a tensor into a list of subtensors using the tf.split funciton, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'T8:0' shape=(1, 3, 2) dtype=float64>, <tf.Tensor 'T8:1' shape=(1, 3, 2) dtype=float64>]\n"
     ]
    }
   ],
   "source": [
    "with g.as_default():\n",
    "    t5_splt = tf.split(T5, num_or_size_splits=2, axis=2, name='T8')\n",
    "    print(t5_splt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here, it's important to note that the output is not a tensorr object anymore ; rather it's a lsit of tensor. The name of these subtensors are 'T8:0' and 'T8:1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__ Concatenation__ Another useful transfromation is the concatenation of multiple tensors. If we have a lsi of tesnors with the same shape and _dtype_ we can combine them into one big tensor using the _tf.concat_ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"t1:0\", shape=(10, 1), dtype=float32)\n",
      "Tensor(\"t2:0\", shape=(10, 1), dtype=float32)\n",
      "Tensor(\"t3:0\", shape=(20, 1), dtype=float32)\n",
      "Tensor(\"t4:0\", shape=(10, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    t1 = tf.ones(shape=[10,1], dtype=tf.float32, name='t1')\n",
    "    t2 = tf.zeros(shape=[10,1], dtype=tf.float32, name='t2')    \n",
    "    \n",
    "    print(t1)\n",
    "    print(t2)\n",
    "    \n",
    "with g.as_default():\n",
    "    t3 = tf.concat([t1,t2], axis=0, name='t3')\n",
    "    print(t3)\n",
    "    t4 = tf.concat([t1,t2], axis=1, name='t4')    \n",
    "    print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]]\n",
      "\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    print(t3.eval())\n",
    "    print()\n",
    "    print(t4.eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Control flow mechanics in building graphs\n",
    "\n",
    "- TensorFlow provides a mechanism for making decisons when building a graph. However, there are some subtle differences when we use Pythong's contorl flow statements compared to TensorFlow's flow funcitons. when construtting computation graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object :  Tensor(\"result_add:0\", dtype=float32)\n",
      " X < y True - Result:  3.0\n",
      " X < y False - Result:  3.0\n"
     ]
    }
   ],
   "source": [
    "## Using naive Python's if statement to build a graph that corresponds to the preceding equation:\n",
    "\n",
    "x, y = 1.0, 2.0\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_x = tf.placeholder(dtype=tf.float32, shape=None, name='tf_x')\n",
    "    tf_y = tf.placeholder(dtype=tf.float32, shape=None, name='tf_y')    \n",
    "    \n",
    "    if x < y:\n",
    "        res = tf.add(tf_x, tf_y , name='result_add')\n",
    "    else:\n",
    "        res = tf.subtract(tf_x, tf_y , name='result_sub')\n",
    "    print('Object : ', res)\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    print(' X < y % s - Result: ' %(x < y),\n",
    "         res.eval(feed_dict= {'tf_x:0': x, 'tf_y:0':y}))\n",
    "    x, y = 2.0 , 1.0\n",
    "    print(' X < y % s - Result: ' %(x < y),\n",
    "         res.eval(feed_dict= {'tf_x:0': x, 'tf_y:0':y}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can see, the _res_ object is a tensor named 'result_add:0'. It is very important to understand that in the previos mechanism , the computatio grpah has boly one brnacnh asoscaited iwth the additon operator, and the suntact operator has not been called.\n",
    "\n",
    "The TensorFlow computation __graph is static. which menat that once the computation graph is built, it remains unchanged during the executiong process.__ so, even when we change the values of x and y and feed the new values to the graph, these new tensors will go trhought he same path in the graph. Therefore, in bothe cases, we see the same ouptut 3.0 for x=2, y=1, and for x =1, y=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object :  Tensor(\"cond/Merge:0\", dtype=float32)\n",
      " X < y True - Result:  3.0\n",
      " X < y False - Result:  1.0\n"
     ]
    }
   ],
   "source": [
    "## Let's use the control flow mechnaics in TensorFlow.\n",
    "\n",
    "\n",
    "x, y = 1.0, 2.0\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_x = tf.placeholder(dtype=tf.float32, shape=None, name='tf_x')\n",
    "    tf_y = tf.placeholder(dtype=tf.float32, shape=None, name='tf_y')    \n",
    "    \n",
    "    res = tf.cond(tf_x < tf_y, \n",
    "        lambda: tf.add(tf_x, tf_y , name='result_add'),\n",
    "        lambda: tf.subtract(tf_x, tf_y , name='result_sub'))\n",
    "    print('Object : ', res)\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    print(' X < y % s - Result: ' %(x < y),\n",
    "         res.eval(feed_dict= {'tf_x:0': x, 'tf_y:0':y}))\n",
    "    x, y = 2.0 , 1.0\n",
    "    print(' X < y % s - Result: ' %(x < y),\n",
    "         res.eval(feed_dict= {'tf_x:0': x, 'tf_y:0':y}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here, we can see that the res object is name \"cond/Merge:0\" . In this case, the computation graph has two branches with a mechanism to decide which branch to follow at execution time. Therefore, when x-2m y=1, it follows thd addition branch and the ouptut will be 3.0 while for x=1, y-2 , the subtracitn branch is pursued and the result will be 1.0\n",
    "\n",
    "In addition, to _tf.cond_ TensorFlwo offfers wevral other conrol flow operators, such as _ tf.case _ and tf.while_loop . For instnace, _ tf.case _ is the TensorFlow contorl flow equivlaent to a python if..else statement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if x < y :\n",
    "    result = 1\n",
    "else:\n",
    "    result = 0\n",
    "# Teh tf.case equivalne is;\n",
    "\n",
    "f1 = lambda: tf.constant(1)\n",
    "f2 = lambda: tf.constant(0)\n",
    "\n",
    "result = tf.cond([(tf.less(x,y), f1)], default=f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Similary we can add a while loop to a TensorFlow graph that increments the i variable by 1 until a threshold\n",
    "# vlaue is reached\n",
    "\n",
    "i = tf.constant(0)\n",
    "threshold = 100\n",
    "c = lambda i: tf.less(i, 100)\n",
    "b = lambda i: tf.add(i, 1) \n",
    "r = tf.while_loop(cond=c, body=b, loop_vars=[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the graph with TensorBoard\n",
    "\n",
    "- Great feature of TensorFlow is TensorBoard, which is a module for visualizing he graph as weel as visualizing the learning of a model. Visualizng the graph allows s to see the connection between nodes, eplore their dependencies and debug the model if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Let's visualize the graph  we build before.\n",
    "\n",
    "batch_size = 64\n",
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    tf_X = tf.placeholder(shape= (batch_size, 100), dtype=tf.float32, name='tf_X')\n",
    "\n",
    "    ## build the geneartor\n",
    "    with tf.variable_scope('generator'):\n",
    "        gen_out1 = build_generator(data=tf_X, n_hidden=50)    \n",
    "        \n",
    "    ## build the classifier\n",
    "    with tf.variable_scope('classifier') as scope:\n",
    "        ## classifier for the original data\n",
    "        cls_out1 = build_classifier(data = tf_X, labels=tf.ones(shape=batch_size))\n",
    "        \n",
    "        \n",
    "        ## reuse the classifier for generated data\n",
    "        scope.reuse_variables()\n",
    "        cls_out2 = build_classifier(data= gen_out1[1], labels=tf.zeros(shape=batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that no changes were needed so far for building the graph. So after building the graph, its visualization is tragiht forward. the following lines of code export the graph for visualization pruposesL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    filt_writer = tf.summary.FileWriter(logdir='./logs/', graph=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a new directory: logs/. Now we just need to run the following command in a Linux terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 0.1.5 at http://amit-Lenovo-G570:6006 (Press CTRL+C to quit) ^C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command will print a message, which is a URL address. We can launch Tensorboard by copying the link generated from the execution of above command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
